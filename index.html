<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Harsh Agrawal: Personal Website</title>

    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/freelancer.css" rel="stylesheet">
    <link href="css/timeline.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

    <script src="js/modernizr.js"></script>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-about-me-hidden navbar-brand" href="#page-top">Harsh Agrawal</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#timeline">Timeline</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#about">Publications</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#projects">Projects</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->

        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="row">

                <div class="col-xs-4">
                    <img class="img-responsive img-circle" src="img/dp1.jpg" alt="">
                </div>
                <div class="col-xs-8">
                    <div class="intro-text">
                        <span class="name">Harsh Agrawal</span>
                        <span class="about_me">
                            My research lies at the intersection of computer vision and natural language processing.
                        Currently I am working at Snapchat Research working with an amazing group of people inventing new ways in which
                        we can make sense of large amounts of visual data available on Snapchat. I also lead the amazing Cloud-CV team and
                        actively maintain the open source CloudCV project that aims to make AI research more reproducible.
                        
                        </span>
                        <hr>
                        <span class="skills"> <ul class="list-inline">
                            <li>
                                <a href="https://twitter.com/harsh_092" class="btn-social btn-outline"><i class="fa fa-fw fa-twitter"></i></a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/harsh092" class="btn-social btn-outline"><i class="fa fa-fw fa-linkedin"></i></a>
                            </li>
                            <li>
                                <a href="https://github.com/dexter1691" class="btn-social btn-outline"><i class="fa fa-fw fa-github"></i></a>
                            </li>
                        </ul></span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section id="timeline">
        <div class="container" >
            <div class="row">
                <section id="cd-timeline" class="cd-container">
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Research Engineer</h2>
                            <span>July, 2016</span>
                            <p> Snapchat Research. </p>
                            <p> Inventing the next generation of creative tools to “empower people to express themselves, live in the moment, learn about the world, and have fun together.”</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>M.S in Computer Engineering</h2>
                            <span>May, 2016</span>
                            <p> Machine Learning and Perception Lab, Virginia Tech. </p>
                            <p> Advisor: Dr. Dhruv Batra</p>
                            <p> Worked on problems at the intersection of computer vision, natural language and machine learning.</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/code.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Organization Administrator for CloudCV</h2>
                            <span>2015, 2016</span>
                            <p> Google Summer of Code (GSOC), '15, '16 </p>
                            <p> Mentored three GSOC students for the summer who contributed to CloudCV as part of Google Summer of Code, 2015.</p>

                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Software Engineer Intern</h2>
                            <span>June - August, 2015</span>
                            <p> Microsoft Dynamics </p>
                            <p> Worked on applying machine learning techniques to automate work-flows for sales lifecycle in Microsoft Dynamics CRM </p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>B.S. in Computer Engineering</h2>
                            <span>June, 2014</span>
                            <p> Graduated from Delhi College of Engineering </p>
                            <p> Worked on applications of computer vision for an Unmanned Aerial Vehicle.</p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/light-bulb-3.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Visiting Student</h2>
                            <span>June, 2014</span>
                            <p> Machine Learning and Perception Lab, Virginia Tech </p>
                            <p> Advisor: Dr. Dhruv Batra</p>
                            <p> Worked on building the first prototype of CloudCV.</p>
                        </div>
                    </div>

                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/light-bulb-3.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Visiting Student Researcher</h2>
                            <span>September, 2012</span>
                            <p> Mobile and Ubiquitous Computing, IIIT-Delhi </p>
                            <p> Developed  a cloud enabled cell broadcast service based localization algorithms for
                                Android smartphones. Also designed and implemented an algorithm to build mobility profiles for predicting
                                encounters between mobile phone users allowing them to share content locally through
                                bluetooth.
                            </p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/camera_2.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Computer Vision Lead</h2>
                            <span>September, 2010</span>
                            <p> Unmanned Aerial Systems - Delhi Technological University </p>
                            <p> Performed autonomous extraction and segmentation of objects from aerial imagery in natural scenes for Student UAS Competition.
                                Developed a robust, user-friendly GUI on Qt to control camera properties and process the imagery feed acquired wirelessly.</p>

                        </div>
                    </div>
                </section> <!-- cd-timeline -->
            </div>

        </div>
    </section>


    <!-- About Section -->
    <section class="success" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications</h2>
                    <hr class="star-light">
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/SortStory.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Sort Story: Sorting Jumbled Images and Captions into Stories</h4>
                    <p class="pubd">
                        Temporal common sense has applications in AI tasks such as QA, multi-document summarization, and human-AI communication.
                        We propose the task of sequencing -- given a jumbled set of aligned image-caption pairs that belong to a story, the task is
                        to sort them such that the output sequence forms a coherent story. We present multiple approaches, via unary (position) and
                        pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task. As features, we
                        use both text-based and image-based features, which depict complementary improvements. Using qualitative examples, we
                        demonstrate that our models have learnt interesting aspects of temporal common sense.
                    </p>
                    <h4 class="puba">Harsh Agrawal<sup>*</sup>, Arjun Chandrasekaran<sup>*</sup>, Dhruv Batra, Devi Parikh, Mohit Bansal</h4>
                    <div class="pubv">EMNLP(2016) Short Paper</div>
                    <div class="publ">
                        <ul>
                            <li><a href="http://arxiv.org/abs/1606.07493">PDF</a></li>
                            <li><a href="https://www.youtube.com/watch?v=CMRy4Y-ZwGE">AI Guild Podcast #2</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/HumanAttention.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?</h4>
                    <p class="pubd">We conduct large-scale studies on `human attention' in Visual Question Answering (VQA) to understand where humans
                        choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces
                        that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the
                        VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention
                        both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Overall, our experiments show that
                        current attention models in VQA do not seem to be looking at the same regions as humans.
                    </p>
                    <h4 class="puba">Abhishek Das<sup>*</sup>, Harsh Agrawal<sup>*</sup>, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra</h4>
                    <div class="pubv">EMNLP(2016) Short Paper</div>
                    <div class="publ">
                        <ul>
                            <li><a href="http://arxiv.org/abs/1606.03556">PDF</a></li>
                            <li><a href="http://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes">The Verge</a></li>
                            <li><a href="http://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable">Nautilus</a></li>
                            <li><a href="https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/">New Scientist</a></li>
                            <li><a href="https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/">TechRadar</a></li>
                            <li><a href="http://www.techradar.com/news/world-of-tech/robots-and-humans-see-the-world-differently-but-we-don-t-know-why-1324165">MIT Tech Review</a></li>

                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/ObjProposals.jpg" style="width: 180px;">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Object-Proposal Evaluation Protocol is 'Gameable'</h4>
                    <p class="pubd">Object proposals have quickly become the de-facto pre-processing step in a number of vision
                        pipelines (for object detection, object discovery, and other tasks). Their performance is
                        usually evaluated on partially annotated datasets. In this paper, we argue that the choice
                        of using a partially annotated dataset for evaluation of object proposals is problematic -- as
                        we demonstrate via a thought experiment, the evaluation protocol is 'gameable', in the sense
                        that progress under this protocol does not necessarily correspond to a "better" category
                        independent object proposal algorithm.
                    </p>
                    <h4 class="puba">Neelima Chavali<sup>*</sup>, Harsh Agrawal<sup>*</sup>, Aroma Mahendru<sup>*</sup>, Dhruv Batra</h4>
                    <div class="pubv">CVPR 2016 (Spotlight)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://filebox.ece.vt.edu/~aroma/web/object-proposals.html">Project</a></li>
                            <li><a href="http://arxiv.org/abs/1505.05836">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV/object-proposals">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="http://cloudcv.org/static/img/Page-1.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">CloudCV: Large Scale Distributed Computer Vision as a Cloud Service</h4>
                    <p class="pubd">
                        We are witnessing a proliferation of massive visual data. Unfortunately scaling existing
                        computer vision algorithms to large datasets leaves researchers repeatedly solving the same
                        algorithmic, logistical, and infrastructural problems. Our goal is to democratize computer
                        vision; one should not have to be a computer vision, big data and distributed computing expert
                        to have access to state-of-the-art distributed computer vision algorithms. We present CloudCV,
                        a comprehensive system to provide access to state-of-the-art distributed computer vision
                        algorithms as a cloud service through a Web Interface and APIs.
                    </p>
                    <h4 class="puba">Harsh Agrawal, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali, Prakriti Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra</h4>
                    <div class="pubv">Book Chapter: Mobile Cloud Visual Media Computing, 265-290</div>
                    <div class="publ">
                        <ul>
                            <li><a href="http://cloudcv.org">Project</a></li>
                            <li><a href="http://http://arxiv.org/abs/1506.04130">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Portfolio Grid Section -->
    <section id="projects">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Projects</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="row">
                <div class="col-xs-offset-3 col-xs-6 col-sm-offset-0 col-sm-4 portfolio-item">
                    <a href="#portfolioModal1" class="portfolio-link" data-toggle="modal">
                        <img src="img/cloudcv-logo.png" class="img-responsive img-circle" alt="">
                    </a>
                </div>
                <div class="col-xs-offset-3  col-xs-6 col-sm-offset-0 col-sm-4 portfolio-item">
                    <a href="#portfolioModal2" class="portfolio-link" data-toggle="modal">
                        <img src="img/aarush_x1.png" class="img-responsive img-circle" alt="">
                    </a>
                </div>
                <div class=" col-xs-offset-3 col-xs-6 col-sm-offset-0 col-sm-4 portfolio-item">
                    <a href="#portfolioModal3" class="portfolio-link" data-toggle="modal">
                        <img src="img/garuda_big_2.png" class="img-responsive img-circle" alt="">
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="text-center">
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        Copyright &copy; Harsh Agrawal 2016
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-xs visible-sm">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>CloudCV</h2>
                            <hr class="star-primary">
                            <img src="img/cloudcv-logo.png" class="img-responsive img-centered" alt="">
                            <p>We are witnessing a proliferation of massive visual data. Unfortunately scaling existing
                                computer vision algorithms to large datasets leaves researchers repeatedly solving the same
                                algorithmic, logistical, and infrastructural problems. Our goal is to democratize computer
                                vision; one should not have to be a computer vision, big data and distributed computing expert
                                to have access to state-of-the-art distributed computer vision algorithms. We present CloudCV,
                                a comprehensive system to provide access to state-of-the-art distributed computer vision
                                algorithms as a cloud service through a Web Interface and APIs.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="http://github.com/Cloud-CV">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://summerofcode.withgoogle.com/organizations/5746858777378816/">GSOC</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Aarush X-1</h2>
                            <hr class="star-primary">
                            <img src="img/aarush_x1.png" class="img-responsive img-centered" alt="">
                            <p>Aarush is a prototype of the UAV developed with financial resources and engineering mentoring support
                                from Lockheed Martin Corporation. Traffic Management, Geomatics, Mining Surveillance, Border patrol
                                are just some of the areas in which this UAV can be put to effective, efficient use. Salient features include: </p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://uasdtu.com/systems.htm">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://www.youtube.com/watch?v=BL-Rbf3iEKI">Flight Video</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Garuda</h2>
                            <hr class="star-primary">
                            <img src="img/garuda_big_2.png" class="img-responsive img-centered" alt="">
                            <p>GARUDA, a modified Sig Rascal 110 R/C aircraft along with its Ground Control System is capable of performing
                                autonomous flight & navigation, simultaneously gathering actionable surveillance data using optical sensors.
                                The system includes commercially available autopilot system, Piccolo II for control & navigation with a customized
                                imagery system capable of capturing & transmitting high definition images of the hostile territory simultaneously
                                processing it to deliver actionable intelligence. The Ground Control Station (GCS) and the aircraft communicate
                                in real time to provide situational awareness and safe and reliable flight. Due to it's modular design, the entire system
                                can be brought to a flying state in less than 20 minutes.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://uasdtu.com/systems.htm">Website</a>
                                    </strong>
                                </li>

                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <script src="js/timeline.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/freelancer.js"></script>

</body>

</html>
